import json
import logging
from typing import List
from ..schemas.dto import SuggestionDTO

# Configure a logger for this module.
logger = logging.getLogger(__name__)

def get_suggestions_from_llm(summary_pack: str) -> str:
    """
    Sends a dataset summary to an LLM and returns its raw JSON response.

    Args:
        summary_pack (str): The text summary generated by the profiling service.

    Returns:
        str: A raw string, which is expected to be a JSON array of suggestions.
    """
    logger.info("--- MOCK LLM CLIENT ---")
    logger.info("Received summary pack. Generating mock LLM response.")
    # In a real implementation, you would construct a prompt and send `summary_pack`
    # to an LLM API endpoint here.

    # This is a hardcoded response that mimics a real, successful LLM output.
    # It ensures we can test the entire application flow.
    mock_response = [
        {
            "title": "Total Sales by Product Category",
            "insight": "This bar chart reveals that 'Electronics' is the highest-selling category, suggesting it's a key driver of revenue.",
            "parameters": {
                "chart_type": "bar",
                "x_axis": "Product Category",
                "y_axis": "Total Sales",
                "aggregation": "sum"
            }
        },
        {
            "title": "Sales Trend Over Time",
            "insight": "This line chart illustrates a consistent upward trend in sales month-over-month, with a significant peak in December.",
            "parameters": {
                "chart_type": "line",
                "x_axis": "Date",
                "y_axis": "Total Sales",
                "aggregation": "sum"
            }
        },
        {
            "title": "Regional Sales Distribution",
            "insight": "A pie chart showing the sales distribution across regions. The 'North' region accounts for the largest share of sales.",
            "parameters": {
                "chart_type": "pie",
                "x_axis": "Region",
                "y_axis": "Total Sales",
                "aggregation": "sum"
            }
        },
        {
            "title": "Regional Sales Distribution",
            "insight": "A pie chart showing the sales distribution across regions. The 'North' region accounts for the largest share of sales.",
            "parameters": {
                "chart_type": "pie",
                "x_axis": "Region",
                "y_axis": "Total Sales",
                "aggregation": "sum"
            }
        }
    ]

    # The LLM is expected to return a JSON string, so we dump our mock object to a string.
    return json.dumps(mock_response)